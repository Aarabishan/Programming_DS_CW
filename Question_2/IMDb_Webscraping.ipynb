{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd336911-a93e-4bc8-89e1-d15344a0c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping IMDb Top 250 Movies using Selenium and BeautifulSoup\n",
    "# ChromeDriver is installed using the webdriver_manager module to automatically manage the ChromeDriver version.\n",
    "# This script loads the IMDb Top 250 page using Selenium,and then parses the HTML content using BeautifulSoup to extract movie data.\n",
    "# Finally verified the scrape function for the further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dcdaed-fac1-4e9f-9cee-1b5f1fb02e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (4.29.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04d4309-638e-47aa-ad36-d477663fba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb Top 250 Movies\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Define IMDb Top 250 URL\n",
    "IMDB_URL = \"https://www.imdb.com/chart/top/\"\n",
    "\n",
    "def scrape_imdb_movies_with_selenium():\n",
    "    # Automatically install and manage ChromeDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    # Set user-agent to avoid bot detection\n",
    "    options = Options()\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    driver.get(IMDB_URL)\n",
    "    time.sleep(3)  # Wait for the page to load completely\n",
    "\n",
    "    # Extract page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()  # Close the browser\n",
    "\n",
    "    return soup\n",
    "\n",
    "# Verifying the scrape function\n",
    "soup = scrape_imdb_movies_with_selenium()\n",
    "print(soup.title.text)  # Should print IMDb page title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643baa3c-4f5a-4d15-871b-d1817147f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d002c5f0-ed26-4dd4-8b3c-62dd945374b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed the webscraping and saved the dataset.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Extract movie data\n",
    "movies_data = []\n",
    "movie_rows = soup.select(\".ipc-metadata-list-summary-item\")  # Updated selector for movie rows\n",
    "\n",
    "if not movie_rows:\n",
    "    print(\"No movie data found. Check the HTML structure.\")\n",
    "else:\n",
    "    for movie in movie_rows:\n",
    "        # Extract movie title\n",
    "        title_element = movie.select_one(\"h3\")\n",
    "        title = title_element.text.strip() if title_element else \"Unknown\"\n",
    "        \n",
    "        # Extract release year\n",
    "        year_element = movie.select(\".sc-f30335b4-7\")\n",
    "        year = year_element[0].text.strip() if year_element else \"Unknown\"\n",
    "        \n",
    "        # Extract IMDb rating\n",
    "        rating_element = movie.select_one(\".ipc-rating-star--imdb\")\n",
    "        rating = rating_element.text.strip() if rating_element else \"Unknown\"\n",
    "        \n",
    "        # Extract movie link\n",
    "        movie_link_element = movie.select_one(\"a.ipc-title-link-wrapper\")\n",
    "        movie_link = \"https://www.imdb.com\" + movie_link_element[\"href\"] if movie_link_element else \"\"\n",
    "        \n",
    "        # Initialize extra details\n",
    "        genre, directors, box_office_revenue, lead_actors = \"Unknown\", \"Unknown\", \"Unknown\", \"Unknown\"\n",
    "        \n",
    "        # Fetch individual movie page for more details\n",
    "        if movie_link:\n",
    "            movie_response = requests.get(movie_link, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "            if movie_response.status_code == 200:\n",
    "                movie_soup = BeautifulSoup(movie_response.text, \"html.parser\")\n",
    "                \n",
    "                # Extract genre\n",
    "                genre_elements = movie_soup.select(\".ipc-chip-list__scroller a\")\n",
    "                genre = \", \".join([g.text.strip() for g in genre_elements]) if genre_elements else \"Unknown\"\n",
    "                \n",
    "                # Extract directors (Avoid duplication)\n",
    "                director_elements = movie_soup.select(\".ipc-metadata-list-item__content-container a[href*='/name/']\")\n",
    "                directors_set = {d.text.strip() for d in director_elements}  # Use a set to avoid duplicates\n",
    "                directors = \", \".join(directors_set) if directors_set else \"Unknown\"\n",
    "                \n",
    "                # Extract box office revenue\n",
    "                box_office_element = movie_soup.select_one(\".ipc-metadata-list__item:-soup-contains('Gross worldwide')\")\n",
    "                box_office_revenue = box_office_element.text.strip().split(\":\")[-1] if box_office_element else \"Unknown\"\n",
    "                \n",
    "                # Extract lead actors (Updated method)\n",
    "                metadata_sections = movie_soup.find_all(\"li\", class_=\"ipc-metadata-list__item\")\n",
    "                for section in metadata_sections:\n",
    "                    if section.find(string=\"Stars\"):\n",
    "                        actor_elements = section.find_all(\"a\", href=lambda x: x and \"/name/\" in x)\n",
    "                        lead_actors_set = {actor.text.strip() for actor in actor_elements}\n",
    "                        lead_actors = \", \".join(lead_actors_set) if lead_actors_set else \"Unknown\"\n",
    "                        break\n",
    "        \n",
    "        movies_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"Rating\": rating,\n",
    "            \"Genre\": genre,\n",
    "            \"Director(s)\": directors,\n",
    "            \"Box Office Revenue\": box_office_revenue,\n",
    "            \"Lead Actors\": lead_actors,\n",
    "        })\n",
    "\n",
    "    # Save to a DataFrame\n",
    "    df = pd.DataFrame(movies_data)\n",
    "    df.to_csv(\"imdb_top_movies.csv\", index=False)\n",
    "    print(f\"Completed the webscraping and saved the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c537ef-1b51-4ceb-8677-38a89c9ce2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
